# Database Configuration (alembic/env.py)
# PostgreSQL database URL (asyncpg driver)
# Format: postgresql+asyncpg://user:password@host:port/database
DATABASE_URL=postgresql+asyncpg://postgres:password@127.0.0.1:5432/stock_bot_db

# Server Configuration (main.py)
# Host address to bind the server
HOST=0.0.0.0
# Port number for the server
PORT=8000

# Telegram Bot Configuration (bot/telegram.py)
# Telegram Bot Token from @BotFather
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
# Password for bot authentication
TELEGRAM_BOT_PASSWORD=your_secure_password_here

# Edgar Tools Configuration
# Edgar identity for SEC filings (format: "Your Name your.email@example.com")
# Required by SEC EDGAR API to identify your application
EDGAR_IDENTITY=Your Name your.email@example.com

# Ollama Configuration
# Base URL for Ollama API server
# Used by both LLM and Embedding when their respective providers are set to "ollama"
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# LLM Configuration (analysis/llm_module.py)
# LLM provider (options: ollama, groq, openai, vllm, anthropic)
# - ollama: Local Ollama server (requires OLLAMA_BASE_URL)
# - groq: Groq API (requires GROQ_API_KEY)
# - openai: OpenAI API (requires OPENAI_API_KEY)
# - vllm: vLLM server (requires VLLM_BASE_URL)
# - anthropic: Anthropic Claude (not yet implemented)
LLM_PROVIDER=ollama
# LLM model name (provider-specific model name)
# Examples: qwen3:8b (ollama), llama-3.1-70b-versatile (groq), gpt-4o (openai)
LLM_MODEL=qwen3:8b
# Groq API key (required when LLM_PROVIDER=groq)
# Get your API key from https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here
# OpenAI API key (required when LLM_PROVIDER=openai or EMBEDDING_PROVIDER=openai)
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
# vLLM server base URL (required when LLM_PROVIDER=vllm)
# Format: http://host:port/v1
VLLM_BASE_URL=http://localhost:8000/v1

# Embedding Configuration (db/repositories/stock_repository.py)
# Embedding provider (options: ollama, openai, vllm)
# - ollama: Local Ollama server (requires OLLAMA_BASE_URL)
# - openai: OpenAI API (requires OPENAI_API_KEY)
# - vllm: vLLM server (requires VLLM_EMBEDDING_BASE_URL)
EMBEDDING_PROVIDER=ollama
# Embedding model name (provider-specific model name)
# Examples: embeddinggemma (ollama), text-embedding-3-small (openai)
EMBEDDING_MODEL=embeddinggemma
# vLLM server base URL for embeddings (required when EMBEDDING_PROVIDER=vllm)
# Format: http://host:port/v1
VLLM_EMBEDDING_BASE_URL=http://localhost:8000/v1
# Ollama GPU configuration (optional, for embedding model)
# Number of GPUs to use for Ollama embeddings (only applies when EMBEDDING_PROVIDER=ollama)
# Leave empty to use Ollama defaults
OLLAMA_NUM_GPU=

# Stock Collector Configuration (jobs/stock_collector.py)
# Number of tickers to process in each batch for stock data collection
STOCK_DATA_BATCH_SIZE=5
# Number of tickers to process in each batch for stock news collection
STOCK_NEWS_BATCH_SIZE=3
# Delay in seconds between batches
BATCH_DELAY_SECONDS=2.0

# Business Timezone Configuration (utils/common.py)
# Timezone for business operations (report date determination, scheduling)
# Default: Asia/Seoul (KST)
# Examples: Asia/Seoul, America/New_York, Europe/London
BUSINESS_TIMEZONE=Asia/Seoul
